西瓜书
"也到了西瓜成熟的季节"
# 第一章 基础知识

机器学习是通过在“数据”也就是“经验”，基于数据进行“算法”方法归纳，形成结果“模型”。  
计算机科学是研究“算法”的学问、机器学习是研究“学习算法”的学问。

一些基本概念

### 样本 sample

也称为“示例”包含了用于训练或测试机器学习模型的信息。样本可以来自各种类型的数据，包括数值、类别、文本、图像等。。
**属性 attribute**：或特征 feature反应事件或对象在某方面的表现或性质的事项。
**属性值 attribute value** ：属性的取值。
- 属性空间 attribute space 、样本空间 sample space或输入空间：称表示样本的特征向量所在 的空间为样本空间,通常用花式大写的 X 表示  
    特征向量 feature vector：空间每个点的坐标向量。  
    (向量中的元素用分号“;”分隔时表示此向量为列向量,用逗号“,”分隔时表示为行向量)
    

### 数据集

数据集通常用集合来表示,令集合 D = {x1, x2, …, xm} 表示包含 m 个样本的数据集。每个样本有d个属性来描述，则表示为d维样本空间

### 模型 （学习器learner）

从数据中学得模型的过程维“训练”或“学习”。用到的为训练数据training data，数据中每个样本为训练样本training sample，样本的组合为训练集train set

### 标记 label

y值。标记所在的空间成为标记空间或输出空间

- 离散型的标记 – 分类 （二分类、多分类）
    
- 连续性的标记 – 回归
    
- 模型训练阶段有用到标记信息 – 监督学习
    
- 模型训练阶段未用到标记信息 – 无监督学习
    

### 泛化

对未知事物判断的准确 与否才是衡量一个模型好坏的关键,我们称此为“泛化”能力  
“数据决定模型的上限,而算法则是让模型无限逼近上限”

### 分布

通常假设样本空间服从一个未知“分布”D,而 我们收集到的每个样本都是独立地从该分布中采样得到,即“独立同分布”。通常收集到的样本越多,越 能从样本中反推出 D 的信息,即越接近真相。此假设属于机器学习中的经典假设

## 假设空间与版本空间

归纳induction：特殊到一般，泛化generalization  
演绎deduction：一般到特殊，特化 specialization  
假设空间：学习过程中在所有假设 hypothesis组成空间进行搜索，与训练集假设匹配，此空间未假设空间。  
版本空间：一个与训练集一致的“假设集合”，称为版本空间。

## 归纳偏好

不同机器学习算法有不同的偏好。进行模型测试，选用最合适的模型。  
著名的“奥卡姆剃 刀”原则认为“若有多个假设与观察一致,则选最简单的那个”

## 发展历程
1. **早期探索（1950s-1960s）**：
    
    - 1950年代，早期机器学习的研究主要集中在基于规则的系统，这些系统通过手工编写规则来模拟智能行为。
    - 1952年，Arthur Samuel编写了一个跳棋程序，该程序能够通过自我对弈来提高水平，这被认为是机器学习的早期示例。
2. **符号主义时期（1960s-1970s）**：
    
    - 1960年代，符号主义（Symbolism）或符号人工智能（Symbolic AI）开始兴起，它依赖于专家系统和逻辑推理。
    - 1967年，认知心理学和人工智能研究者提出了“感知器”（Perceptron），这是最早的神经网络之一。
3. **连接主义时期（1980s-1990s）**：
    
    - 1980年代，连接主义（Connectionism）开始流行，神经网络研究复兴，特别是反向传播算法的发明，极大地推动了深度学习的发展。
    - 1986年，Rumelhart, Hinton和Williams提出了多层感知器（MLP）和反向传播算法。
4. **统计学习时期（1990s-2000s）**：
    
    - 1990年代，统计学习方法开始受到重视，支持向量机（SVM）、决策树、随机森林、K最近邻（K-NN）等算法被广泛研究和应用。
    - 1997年，Tom Mitchell出版了《机器学习》一书，为机器学习领域提供了经典教材。
5. **大数据与深度学习（2000s-2010s）**：
    
    - 21世纪初，随着大数据的出现和计算能力的提升，机器学习开始处理更复杂的任务，深度学习在图像识别、自然语言处理等领域取得了突破性进展。
    - 2006年，Hinton等人提出了深度信念网络（Deep Belief Network），标志着深度学习时代的到来。
6. **机器学习的广泛应用（2010s-至今）**：
    
    - 2010年代，机器学习开始广泛应用于互联网服务、自动驾驶、医疗诊断、金融分析等众多领域。
    - 2012年，AlexNet在ImageNet竞赛中取得显著成绩，深度学习开始在图像识别领域占据主导地位。
    - 2016年，AlphaGo战胜了世界围棋冠军李世石，标志着机器学习在复杂策略游戏中的重大突破。

### 关于机器学习重要会议

国际机器学习会议ICML、国际神经信息处理系统会议NIPS、国际学习理论会议COLT  
欧洲机器学习会议ECML、亚洲机器学习会议ACML  
人工智能：IJCAI、AAAI  
数据挖掘：KDD、ICDM、

### 关于机器学习重要期刊

journal of machine learning research、machine learning。  
artificial intelligence、 journal of artificial intelligence research  
ACM transactions on knowledge discovery from data、data mining and knowledge discovery  
IEEE transactions on neural networks and learning systems  
annals of statistics

# 第二章 模型评估与选择

## 一些简单指标概念

错误率: E = a /m ,其中 m 为样本个数,a 为分类错误样本个数。  
精度: 精度 =1-错误率。  
误差: 学习器的实际预测输出与样本的真实输出之间的差异。  
经验误差: 学习器在训练集上的误差,又称为“训练误差”。  
泛化误差: 学习器在新样本上的误差。  
过拟合： 由于模型的学习能力相对于数据来说过于强大 （不太容易解决）  
欠拟合： 因为模型的学习能力相 对于数据来说过于低下。（容易解决，扩展分支，迭代）
## 模型评价方法
模型的评估方法通常有：
- 留出法 hold-out：操作简单 训练集S与测试集T互斥  
- 交叉验证法： k折交叉验证 特例是留一法（leave-one-out， LOO）  
- 自助法： 自助法常用于集成学习产生基分类器。随即在原始数据集D取出来一个样本作为新数据集D1，然后放回，再次取样，反复执行m次，得到了包含m个样本的新数据集D1.
## 对模型的修改与性能评价
调参与最终模型:调参：parameter tuning 超参数调整。性能度量:常用的错误率、精度、查准率、查全率、F1、ROC 和 AUC