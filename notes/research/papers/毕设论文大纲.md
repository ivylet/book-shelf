**CG_DESCENT共轭梯度法在压缩感知中的应用**


本课题测试**CG_DESCENT**共轭梯度方法在求解压缩感知问题中数值表现，通过求解光滑的等价模型来检验算法的效果。测试问题来源于模拟数据，要求理解算法的实现过程以及算法以及条件数对算法的影响；其次参数对算法的影响，研究算法的收敛性以及数值表现。


# 摘要

压缩感知问题
本文研究问题

### 关键词
压缩感知 无约束最优化问题 修正三项 PRP 共轭梯度法


# 目录
研究背景与意义
几种无约束优化算法
- 最速下降(负梯度法)法
- 牛顿法
- 拟牛顿法
- 共轭梯度法
几种线搜索
- Armijo线搜索
- Goldstein线搜索
- 标准 wolfe-powell 线搜索
- 强 wolfe-powell 线搜索
共轭梯度法在压缩感知中的应用
- 引言
- 算法
- 全局收敛性
数值实验
- 测试不同算法随着问题规模的残差误差变化
- 测试不同算法随着正则化参数lambda随着原信号维度的残差误差以及



# 第一章 绪论
## 研究背景与意义
传统的信号采样方法要为了不失真地恢复模拟信号，要求离散信号系统的采样频率不小于模拟信号频谱中最高频率的2倍，即满足奈奎斯特定理。但在信息需求量日益增加的情况下，如果采用传统方法会出现得能耗增高，传输速率缓慢等问题，而实际信息获取中对采样速率和处理速度等提出越来越高的要求。因此在处理大规模信号恢复问题时，如何在尽可能减少采样数据，而达到恢复原始信号的效果成为了一个重要的研究方向。而压缩感知技术正是这一研究方向的重要方法之一。

压缩感知技术的研究背景主要包括以下几个方面：

传统采样技术的不足；在实践应用中，获取信号的采样受到很多限制，比如设备存储成成本、设备处理、成本或传输能耗多方面的限制，传统采样技术在这些限制下表现出缺陷。

信号具有稀疏性；在实际应用中，许多待处理信号表现出稀疏性,例如许多自然信号，如图像、语音和生物信号，往往在某些变换域中表现出稀疏性，具有稀疏性的信号往往具有更强的抗干扰能力。

计算复杂度的降低；传统的信号处理方法需要处理大量数据从而导致计算复杂度较高，需要更多计算资源。而压缩感知技术可以通过简化采样过程，以及使用稀疏优化算法，从而在保证信号一定质量的同时降低计算复杂度，减少计算资源的使用。

压缩感知技术的研究意义主要包括以下几个方面：

提高数据采集效率；压缩感知技术可以在传统奈奎斯特率的条件下采集数据，可以显著减少数据的存储和运输成本，这对于提高数据采集的效率和降低采集成本具有重要意义。

增强信号处理的鲁棒性；压缩感知技术利用信号的稀疏性，能够提高信号处理系统对信号中噪声和干扰的抵抗能力，这对于提高信号恢复的准确性和可靠性非常重要。
    
推动新兴技术的发展；压缩感知技术不仅可以与机器学习、人工智能等领域的结合，也可以在新兴应用场景中发挥作用，例如物联网(IoT)、智能城市。压缩感知技术可以为信号的自动分类、特征提取和模式识别提供了新的工具和方法，也可以应对新兴技术挑战。





## 几种无约束最优化算法
无约束优化算法（Unconstrained Optimization Algorithm）是一类用于寻找函数最小值（或最大值）的算法，该算法在使用时无需考虑函数定义域的限制条件。
这些算法主要应用在目标函数在空间中无天然约束或者约束条件可以被忽略的情况下。而无约束优化问题的目标是找到一个点，使得目标函数在这个点的函数值达到最小（或最大）值。

下面介绍几种常见的无约束优化算法：

### 最速下降(负梯度法)法
最速下降法（Steepest Descent Method），也被称为负梯度法（Gradient Descent Method），是一种一阶迭代优化算法，主要用于求解无约束的非线性优化问题。其基本思想是沿着函数值下降最快的方向（即负梯度方向）进行迭代搜索，以求得函数的局部极小值。


最速下降法广泛应用于机器学习、深度学习、数值优化等领域，尤其是在求解大规模优化问题时，由于其计算简单，常作为初始解的求解方法。

最速下降法的使用有一定限制：需要目标函数可微，且梯度容易计算；对于非凸函数，最速下降法可能收敛到局部极小值而非全局极小值；步长的选取对算法的收敛速度有很大影响，需要仔细调整。

### 牛顿法
牛顿法（Newton's method），也称为牛顿-拉弗森方法（Newton-Raphson method），是一种在实数域和复数域上近似求解方程的方法。它使用函数曲线的切线来逐步逼近方程的根。牛顿法是一种迭代法，适用于求解单变量的非线性方程。

### 拟牛顿法
拟牛顿法（Quasi-Newton methods）是一类用于求解无约束优化问题的迭代算法，它们在20世纪50年代由W. C. Davidon提出，并由R. Fletcher和M. J. D. Powell进一步发展。这类方法的核心思想是利用目标函数的一阶导数（梯度）信息来构造一个近似的目标函数模型，从而产生超线性收敛性，同时避免了牛顿法中计算二阶导数（Hessian矩阵）的复杂性。

### 共轭梯度法
共轭梯度法（Conjugate Gradient method），简称CG方法，是一种解决线性方程组的迭代算法，特别是当系数矩阵是大型稀疏矩阵时非常有效。这种方法由M. J. D. Powell在1967年提出，主要用于解决大规模的稀疏线性系统。

### 一种新的共轭梯度法

## 几种线搜索
线搜索（Line Search）是优化算法中用于确定在迭代过程中沿着特定方向移动的步长的方法。其目的是找到一个步长 ，使得目标函数在当前迭代点沿着搜索方向上取得最大的函数值下降。线搜索是许多优化算法，如梯度下降法、牛顿法、拟牛顿法等的关键组成部分。正确选择步长对于算法的收敛速度和全局收敛性至关重要。
一般包括精确线搜索和非精确线搜索
精确线搜索
非精确线搜索
下面介绍几种常见满足非精确的线搜索方法：
### Armijo线搜索
Armijo线搜索是一种常用的非精确线搜索方法，用于确定在梯度下降算法中的每次迭代步长。这种方法旨在找到一个步长 �α，使得目标函数沿着选定的下降方向有“充分”的下降，同时避免步长过大而越过极小值点或步长过小而使得算法收敛缓慢。
优点：
缺点：
Armijo线搜索方法后来被其他更高级的线搜索方法所改进，如Wolfe条件（也称为强Wolfe条件）和Goldstein条件，这些方法在某些情况下提供了更好的性能和更严格的理论保证。
### Goldstein线搜索
Goldstein线搜索是一种非精确线搜索方法，它在优化算法中用于确定在迭代过程中沿着特定方向移动的步长。Goldstein线搜索是Armijo线搜索的一种变体，它通过确保目标函数值在迭代过程中有足够下降的同时，避免了步长过小的问题。
优点：
缺点：
Goldstein线搜索是一种在优化算法中用于确定步长的有用工具，它通过确保函数值的充分下降和梯度下降来指导步长的选取。尽管它有局限性，但通过适当的调整和与其他方法的结合，Goldstein线搜索可以有效地应用于多种优化问题中。
### 标准 wolfe-powell 线搜索
标准Wolfe-Powell线搜索是一种用于优化算法中的非精确线搜索方法，它通过满足两个条件来确保步长的有效性：充分下降条件（Armijo条件）和曲率条件。这种方法旨在找到合适的步长 �α，使得目标函数沿着搜索方向 �d 有充分的下降，并且步长不会过大以至于错过最优点。
优点：
缺点：
在实际实现中，可能需要对步长进行适当的调整以避免陷入局部极小值或错过最优点。此外，为了确保算法的稳定性，通常会设置一个合理的初始步长，并在必要时对 �1c1​ 和 �2c2​ 进行调整。Wolfe-Powell线搜索是一种有效的非精确线搜索方法，它通过两个条件来确保步长的合理性，从而提高优化算法的收敛性和效率
### 强 wolfe-powell 线搜索
强Wolfe-Powell线搜索是标准Wolfe-Powell线搜索的一个变种，它通过引入更严格的条件来改进步长的搜索过程。这种方法特别关注于避免步长过大，从而确保算法不会错过最优点。强Wolfe-Powell线搜索通常用于那些要求更高精度和更严格收敛标准的优化问题。
优点：
缺点：
强Wolfe-Powell线搜索通过引入更严格的曲率条件，提高了步长搜索的精度，有助于优化算法更可靠地收敛到最优点。尽管计算成本可能略高，但在需要高精度解的优化问题中，这种方法是非常有用的。

# 第二章 共轭梯度法在压缩感知中的应用
## 引言
## 算法
## 收敛性分析

# 第三章 数值实验
- 测试不同算法随着问题规模的残差误差变化
- 测试不同算法随着正则化参数lambda随着原信号维度的残差误差以及

============== HS共轭梯度法 ==============
n = 1024, m = 2048, lambda = 100, mu = 0.5
最终相对残差: 0.0286
最终相对误差: 0.6486
耗时: 11.61s